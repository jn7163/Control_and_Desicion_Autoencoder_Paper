% !Mode:: "TeX:UTF-8"

%%%中文版式与英文版式通过参数设置
\documentclass{ctacn}%英文版式

%可以选择使用times字体
\usepackage{newtxtext}
\usepackage{hhline}
\usepackage{ctex}

\begin{document}


%%%%%%%输入年、月、卷、期
\Volume{xxxx}{x}{xxx}{xx}{x}
\cndoi{1001-0920(0000)00-0000-00}
\doi{10.13195/j.kzyjc.0000.0000}
\paperdate{xxxx-xx-xx}{xxxx-xx-xx}%接收日期，修回日期
%%%%%%%设置开始页
\setcounter{page}{1}

%%%%%%%输入页眉显示的题目

%%%%%%%%%%
%%%                  本刊为匿名审稿，新投稿时不要填写任何作者信息，包括所有位置的姓名、单位以及邮箱
%%%%%%%%%%%%
\runheading{基于DropOut降噪自编码的磨矿系统故障诊断}%页眉设置,填写第一作者及论文题目
\xiangmujijin{国家自然基金项目(00000000)}%项目基金  为空会自动取消显示
\authorintro{作者一\,(1974$-$), 男, 教授, 博士, 从事XXX及其应用等研究；作者(1990$-$), 男, 硕士生, 从事XXX的研究.}%作者简介，填写第一作者和导师的简介         %新投稿不修改
\authorcor{E-mail: zuozheyi@163.com}%通讯作者邮箱,新投稿不修改

%%%-------------中文信息---------------
\cntitle{基于DropOut降噪自编码的磨矿系统故障诊断} %输入中文标题


%                  新投稿不要修改下面的姓名及单位
%%%中文作者和单位，\dag代表通信作者，“作者一”代表3个字的名，“作者”代表2个字的名
\cnauthor{作者一\makebox{$^{1,2\dag}$},~~作~~~~者\makebox{$^{1}$}}%新投稿不修改
{(1. 东北大学~信息科学与工程学院，沈阳~110004；2. 曲阜师范大学~工学院, 山东~日照~276826)}%%省会城市无需加省%%新投稿不要修改

%%%中文摘要
\cnabstract{目前磨矿系统的故障诊断主要依靠工人的经验，而这为故障诊断增加了大量不确定性。此外，磨矿系统的数据较为复杂，不仅工人难以对故障的发生进行准确判断，传统机器学习算法也由于数据的线性不可分而表现不佳。为了解决线性不可分的问题，我们使用神经网络进行故障分类；面对故障数据的高复杂度，为提高神经网络的表达能力，我们使用自动编码器增加网络深度；为减弱深层网络带来的过拟合现象，引入DropOut 降噪自编码，最终DropOut降噪自编码网络对于故障的分类准确率达到90.4\%。}

%%%中文关键词
\cnkeyword{故障诊断；自动编码器；DropOut；降噪自编码；Softmax分类器；深度学习}

%%%分类号、标识码
\clc{TP273}%中文分类号
\wenxianbiaoshi{A}%文献标志码

%%%%%%%----------------英文信息------------
\entitle{DropOut Denoising Autoencoder-based Fault Diagnosis for Grinding System}


%%%%%%%              新投稿不要修改下面的英文名及单位
\enauthor{ZUO Zhe-yi\makebox{$^{1,2\dag}$},~~ZUO Zhe\makebox{$^{1}$}}{
(1. College of Information Science and Engineering，Northeastern University，Shenyang~110004，China；2. College of Engineering, Qufu Normal University，Rizhao~276826，China)}


\enabstract{The current fault diagnosis of the grinding system relies mainly on the experience of the workers, which adds a lot of uncertainty to the fault diagnosis. In addition, the grinding system data is too complex, which makes it hard for the workers to judge, and brings about poor performance for traditional machine learning algorithms due to the linear indivisiblity. In order to solve the problem of linear indivisibility, we use neural network for fault classification. In the face of the high complexity of fault data, we use autoencoder to increase network depth in order to improve the expression ability of neural network. To reduce the over-fitting brought about by deep network, we introduce DropOut and denoising autoencoder. Ultimately, the Dropout Denoising Autoencoder (DDA) reached the accuracy of 90.4\% to the fault classification.}

\enkeyword{Fault Diagnosis；Autoencoder；DropOut；Denoising Autoencoder；Softmax Classifier；Deep Learning}

\maketitle




\begin{multicols}{2}
\section{引\quad 言}
磨矿过程是选矿厂生产过程的最重要环节之一，其主要任务是将矿石经过物理的研磨和分级，使有用矿物与脉石单体解离，为后续的选别作业创造条件。

磨矿过程是典型的流程工业过程，生产过程缓慢，滞后时间长，其机理复杂、影响因素多，如给矿量、给水量、原矿性质及装球量等随机变化及各种外界干扰因素，往往造成磨矿过程工作不稳定。现有磨矿分级过程核心设备球磨机的运行监控还仅仅停留在对数据的显示和存储上，没有完整的故障诊断系统为设备的稳定运行保驾护航，根本原因也在于人员因素和技术因素，矿山环境大多恶劣偏僻，难以吸引专业技术人员，而故障诊断的基础是通过操作人员的经验积累人工判断来实现的，而人为控制的过程由于受到种种外界条件的干扰，会对控制结果产生直接或间接的影响。

近年来，网络及数据分析诊断理论的应用越来越发达，通过物联网对现场数据进行传送至生产制造企业，如何通过采集到的现场数据进行挖掘分析，实现高效的故障诊断系统越来越得到矿山生产单位的关注与期待。

本文基于以上问题，使用DropOut降噪自编码算法，实现对V型磨矿系统工作过程中故障智能诊断。

本文首先对采集点长期以来采集到的数据集，对其进行数据预处理：确定输入向量维度、补全缺失数据、清洗噪声数据、定义故障表征方法，并进行数据关联分析建立起样本数据中特征向量与标签数据之间的映射关系。

接下来，搭建传统BP神经网络设置网络参数，输入为没有进行任何特征变换的特征向量，训练网络最终输出的结果效果并不好，可以发现对于高维输入特征向量传统BP神经网络收敛速度慢且辨识效果差。

为了解决传统BP神经网络对高维输入特征向量辨识能力差的问题，在特征向量输入网络之前用自动编码器先进行特征的进一步提取，并将提取到的特征进行非线性变换。在自动编码器网络后面分别级联传统BP网络或Softmax分类器，对构建好的新网络进行训练来对故障进行预测，通过实验进行对比，可以得出结论：在故障预测准确率方面AutoencoderSoftmax（A-S）和AutoencoderBP（A-BP）深度学习网络要优于BP神经网络。然而，原始的自动编码器有着抗干扰性能较弱，泛化能力不强，并且有一定过拟合的缺陷，最后我们分别加入DropOut和使用降噪自编码，并将二者结合到一起，进行对比，最终明显提升了分类准确率。

本文中神经元网络和自编码网络层数及神经元数量为经过多次试验得到，方法为先使用3层网络，逐个增加隐藏层单元节点数量，通过3-fold方法交叉检验进行调优。当准确率不再上升的时候以当前网络结构为基础增加网络层数，继续试验，直到准确率不再上升为止。使用这种方法可以获得使网络分类最有效的最小网络结构。

\section{相关工作}
随着工业生产指标的不断提高，故障诊断技术也得到了一定程度的发展，以不同的角度来看，故障诊断方法可以分成两大类：基于数学模型的故障诊断方法、基于人工智能的故障诊断方法。

基于数学模型的故障诊断方法：

文献\cite{刘强2010基于数据和知识的工业过程监视及故障诊断综述}提出具有复杂数据特性的工业过程的多元统计监视方法,并分别讨论了基于数据和基于知识方法进行故障诊断的优势、进展、适用范围及二者结合的可能。

文献\cite{李勇2006磨矿过程参数软测量与综合优化控制的研究}提出基于主成分分析和贝叶斯网络相结合并简化算法，对不确定性问题的故障诊断，可以去点冗余信息，提高辨识正确率和诊断结果可靠性。

文献\cite{darby2011rto}提出利用未知输入观测器与著名的Beard故障检测滤波器结合的有效故障诊断方法，主要是通过观测器估计系统输出，然后将它与输出的测量值作比较从中获得故障信息。

但是随着现代设备的不断大型化、复杂化和非线性化，往往很难或者无法建立系统精确的数学模型，从而大大限制了基于数学模型的故障诊断方法的推广和应用。

基于人工智能的故障诊断方法：基于数学模型的故障诊断方法对于系统的数学模型线性度有很大的依赖性，导致其有很大的局限性，而近些年出现的基于人工智能的故障诊断方法可以很好的弥补这一缺点。

基于神经网络的人工智能型诊断方法，其采取隐式表示，并将某一问题的若干知识表示在同一网络中，通用性高、便于实现知识的总体获取和并性联想推理。

文献\cite{scattolini2009architectures}提出基于模糊神经网络多数据融合的智能料位检测方法，将多传感器采集的变量参数按照模糊规则进行模糊化处理，并构造神经网络进行数据融合。

文献\cite{ranaee2010application}针对神经网络极易陷入局部极小的问题,采用引入动量项和混沌映射的改进BP算法,讨论引入动量项和混沌映射的神经网络综合模型的建模思路及其算法实现,建立球磨机故障诊断的混沌神经网络模型。

文献\cite{garrido2011extended}采用多层感知器神经网络和系统辨识相结合的方法,运用Matlab系统辨识工具箱和神经网络工具箱,提出了由线性模型和非线性补偿模型组成的混合模型结构的精矿品位预报方法,建立了精矿品位预报模型。

传统的神经网络模型，优点：分类的准确度高，有较强的鲁棒性和容错能力，能够处理复杂的非线性函数并充分逼近复杂的非线性关系，并且能发现不同输入间的依赖关系；缺点：需要大量的参数，学习过程无法观察且学习时间长。

基于故障树（决策树）的人工智能型诊断方法，故障树方法是由电脑依据故障与原因的先验知识和故障率知识自动辅助生成故障树，并自动生成故障树的搜索过程。

文献\cite{dazhi2011research}针对故障诊断面临的故障样本少、非线性强、多故障处理等问题以及传统智能诊断方法存在的不足,提出了一种基于决策树(DT)和相关向量机(RVM)的智能故障诊断方法。通过构造决策二叉树,将多类分类问题分解成多个二类分类问题;在各个决策节点,利用RVM进行二类分类,从而实现RVM的多类分类。

其优点在于能够同时处理分类数据和数值数据，很容易处理变量之间的相互影响，适合小规模数据；缺点就是不擅长对数值结果进行预测。

文献\cite{vincent2010stacked}基于自动编码器容易受噪声干扰而拟合噪声信息，导致过拟合的特点，通过在训练过程中随机将节点的连接权变为0的方式引入噪声，提出了降噪自编码，显著地提高了分类器的性能，以无监督的方式在一些情况下超越了深度信念网络。

文献\cite{srivastava2014dropout, hinton2012improving}引入了DropOut技术，通过在训练过程中随机丢弃节点，使用了来自不同“稀疏”网络的进行训练。在测试时，通过简单地使用具有较小权重的单个无连网的网络来估计所有这些稀疏网络的预测的平均效果。这显着减少过度拟合并对其他正则化方法有着重大改进。最终该方法在图像识别、语音分类等领域都实现了最先进的效果。

文献\cite{石鑫2016基于深度自编码网络的电力变压器故障诊断}提出了基于深度网络的电力变压器故障诊断方法，工程实例测试结果表明，该方法正确可行，诊断性能优于三比值、神经网络和支持向量机的方法，适用于电力变压器的故障诊断。

综上所述方法各有优缺点和其各自的适用性。深度学习的优点在于可以较好地拟合数据，而缺点在于对数据量的需求过大，数据量不足会导致严重的过拟合。而这正适用于由于球磨机产生的数据特点：大数据、多变量、强耦合和大惯性。本文采用Autoencoder和Softmax结合的深度学习算法，并加入降噪与DropOut来实现对大数据进行分析研究预测故障类型。自动编码器主要是对数据进行无损压缩处理，就可以解决高维数据的处理压力；Softmax分类器网络实际上是logistic回归模型在多分类问题上的广，二者结合起来可以实现对于高维输入数据高精度的分类。引入降噪与DropOut可以显著降低过拟合，提高网络泛化能力。


\end{multicols}
\begin{center}
	\tabcaption{故障原因及表征方法表}
	\renewcommand\tabcolsep{12.6pt}%调整表格长度
	\label{tab1}
	\renewcommand\tabcolsep{10pt}
	\begin{tabular}{ccc}\toprule
	故障现象&故障原因&故障表征\\
	\hline
	正常&无&10000000\\
	给矿压力低&进料端矿箱漏矿&01000000\\
	给矿压力增大&旋流器穿孔&00100000\\
	主电机电流低，离合器气罐压力低&气缸故障&00010000\\
	主电机前后轴瓦、邮箱温度高，高压供油压力低&稀油站冷却水阀门损坏&00001000\\
	主轴瓦给料右温度上升，供油压力给料右下降&油压低，轴瓦温度高&00000100\\
	主轴瓦排料右温度升高，供油流量排料下降低&流量低，轴瓦温度升高&00000010\\
	主电机温度高&油温高，油压低&00000001\\
	\bottomrule
	\end{tabular}
\end{center}
\begin{multicols}{2}


\section{基于BP网络进行故障检测}

\subsection{数据与处理及分析}
本文以V型磨矿系统岗位记录提供的数据集作为依托，通过对数据集进行分析研究实现对磨矿系统在运行过程中所出现的故障进行分类预测。数据集的形式为每隔一个小时系统在采集点（温度、压力、声音、振动等）所采集到的数据，共计1024个小时，30种测量指标。

如果直接对这1024组30维度的数据进行分析处理，显然会比较困难。我们发现，在这30种测量指标中，有很多特征是不会发生变化的，故分析之前可以先将这些数据剔除掉，这样数据集的纵向维度由30维下降为24维。数据集中还存在许多缺失的数据，对于这些数据，本文采用对缺失数据点前后5小时之内的数据进行求均值的方法填充缺失数据。

磨矿生产过程中的故障一般分为磨矿设备如球磨机的故障和生产工艺故障如物料输入输出的失衡等。本文主要针对项目所给数据集中的故障进行分析，最终的目的是要对故障进行诊断，因此，这些故障的类型被看作标签（label）。对于这些数据的表征，本文采用“one-hot vector”表示，即对于第几类故障则在对应的位置上为1，其余的位置上为0，相当于利用二进制编码。本文一共划分为8类故障，所以“one-hot vector”为一个8维二进制向量。

\begin{center}
	\includegraphics[scale=0.7, trim=0 0 0 0]{figs/data_features}\\
	\label{fig1}
	\figcaption{第0.1维特征分类图}
\end{center}

由表1可以看出，故障种类共分为进料端矿箱漏矿、旋流器穿孔、气缸故障等8类故障，其中的几类还有较强的相关性，比较难以辨识。通过分析数据，建立特征向量和目标之间的映射关系时发现：1024组特征向量对应的标签中有877类为无故障，147类为有故障，为严重的不均衡分类情况。这里我们选择了其中的两维特征进行分析如图1所示。

由图1可以看出8类故障中第一类故障也就是无故障类别所占比例很大，而其他几类故障所占的比例相对第一类故障所占的比重要小很多，这是严重的不均衡分类问题，并且，故障分布较分散，特征不显著，不利于分类器进行分类。因此，问题处理过程中对于占比重较小的故障类对其分类正确率不宜作为评判指标。

\subsection{BP网络的建立}

首先，人工神经网络对于知识有较强的学习能力，它对数据的并行处理能力可大大提高其处理信息的能力的速度。基于这种思想，我们将神经网络技术应用于磨矿生产过程中的诊断，从而获得理想的诊断效果。

目前应用较多前馈型网络的是BP网络，其学习速度快，逼近能力和分类能力强。本文使用BP神经网络来对磨矿中的故障进行诊断，诊断系统功能结构如图2所示。

\begin{center}
	\includegraphics[scale=0.12, trim=0 0 0 0]{figs/procedure}
	\label{fig2}
	\figcaption{磨矿神经网络故障诊断功能示意图}
\end{center}

传统的BP神经网络在训练过程中，容易陷入局部极小点。为解决这个困难，本文采用“批量训练”的训练方法，这种方法在训练神经网络的过程中，不受学习样本排序的影响，使收敛速度加快。此外，为使训练不同时期都能获得较好的学习率，采用了学习率自调整的方法。本文构建的BP神经网络的模型为三层神经网络，即输入层，隐层和输出层三层。在样本数据输入网络之前，由于数据之间不存在很大的相关性，且数量级之间存在较大的差异，所以本文将数据进行归一化处理后，再进行数据输入。

\subsection{实验与结果分析}

本文分别采用$1024\times24$维的整体数据集划分为$900\times24$维的数据作为训练样本集，剩下的$124\times24$维数据作为测试集，进行验证可以防止网络过拟合。在训练样本集输入到网络时，进行分批处理，即每次输入$32\times24$维的数据，训练好网络后保存其权重和阈值，测试集再输入到训练好的网络中，来验证网络可靠性和诊断的准确率。

训练样本集输入后网络的输出从大的层面上讲分为两类：一是有无故障；二是已经判断出来有故障，对于有故障的数据接下来进行进一步的分析是哪一类故障。本文中的故障辨识问题不是传统的分类问题，其存在着严重的分类不均衡问题。在非均衡分类中的主要评价指标可以利用混淆矩阵给出，如表2所示。


\begin{center}
	\tabcaption{混淆矩阵表}
	\label{tab:2}
	\begin{tabular} {cccc}\toprule
		\multirow{2}{*}[-2pt]{}&\multirow{2}{*}[-2pt]{}&\multicolumn{2}{c}{预测结果}\\
		\cmidrule(lr){3-4}
		&&$+1$&$-1$\\\hline
		\multirow{2}{*}[-2pt]{真实结果}&$+1$&真正例（TP）&伪反例（FN）\\
		&$-1$&伪正例（FP）&真反例（TN）\\
		\bottomrule
\end{tabular}\end{center}

这里以简单的二值分类问题进行说明，在二值分类问题中，如果将一个正例判为正例，那么就认为产生了一个真正例（True Positive，TP，也称真阳）；如果对一个反例正确地判为反例，则认为产生了一个真反例（True Negative，TN，也称真阴）。相应地，另外两种情况则分别称为伪反例（Flase Negative，FN，也称假阴）和伪正例（False Positive，FP，也称假阳），这四种情况如表2所示。

在分类问题中，当某个类别的重要性高于其他类别时或者存在不均衡分类时，我们就可以利用上述定义来构造出多个比错误率更加适合作为衡量标准的新指标。

本文中将有故障当作正例，没有故障当作反例，定义了如下评价指标：

（1）错误率$S_1$：
\begin{align}
S_1=1-\frac{TP+TN}{TP+FP+TN+FN}
\end{align}

这个指标对于不存在非均衡分类和当某个类别的重要性高于其他类别时较为实用，在本问题中不是特别适合，仅为一个参考评价指标。

（2）预测有故障正确率$S_2$（正例正确率）：
\begin{align}
S_2=\frac{TP}{TP+FP}
\end{align}

这个指标给出的是预测为正例样本中的真正例的比例。若在本次实验中分类器对数据集进行预测分类时得出$N$个样例为有故障类别；且在这$N$个预测有故障的类别里面有$n$个是真正的有故障类别，那么正例正确率即预测有故障正确率为$n/N$。

（3）预测无故障正确率$S_3$（反例正确率）：
\begin{align}
S_3=\frac{TN}{TN+FN}
\end{align}

这个指标给出的是预测为反例的样本中真正反例的比例。若在本次实验中分类器对数据集进行预测分类时得出$M$个样例为有故障类别，且在这$M$个预测有故障的类别里面有$m$个是真正的有故障类别，那么正例正确率即预测无故障正确率为$m/M$。

对传统的BP神经网络进行实验验证，实验结果如下：


\begin{center}
	\tabcaption{BP神经网络实验结果}
	\label{tab:3}
	\begin{tabular} {cccc}\toprule
		\multirow{2}{*}[-2pt]{}&\multirow{2}{*}[-2pt]{}&\multicolumn{2}{c}{预测结果}\\
		\cmidrule(lr){3-4}
		&&有故障&无故障\\\hline
		\multirow{2}{*}[-2pt]{真实结果}&有故障&21&24\\
		&无故障&24&55\\
		\bottomrule
\end{tabular}\end{center}

通过实验结果可以计算出不作任何特征变换的BP神经网络，神经元网络激活函数使用Sigmoid函数，节点大小为$24\rightarrow100\rightarrow8$，对于预测有故障的正确率为46.7\%，无故障的正确率为69.6\%，错误率为38.7\%。可以看出，如果对于输入的特征向量不作任何特征变化就输入到神经网络中，网络在有无故障的辨识正确率方面表现都比较差，并且错误率较高。这也进一步说明传统BP神经网络不适用高维输入的非均衡分类问题。

\section{原始自动编码器}

本文中的训练样本集的输入维数为24维，但对于神经网络来说，输入的维数越高对于神经网络的训练会越困难，因此可以运用类似于特征压缩的技术对训练样本输入进行进一步无监督地特征提取。基于此，我们使用自动编码器对特征进行自动编码。

自编码神经网络是一种无监督学习算法，在训练时它让其输出值等于输入值。如果神经网络隐藏层神经元个数远小于输入层和输出层，这样就迫使自编码神经网络去学习输入数据的压缩表示，假设神经网络的输入是完全随机的数据，要学习这些随机数据的压缩表示是十分困难的；如果某些特征之间是彼此相关的，自编码算法就能发现这些有联系数据间的相关性，并能在输出层重构出输入数据。相反，如果神经网络的隐层神经元个数较多或与输入层相当时，还可以对隐藏层神经元上加上稀疏性限制，这样自编码神经网络仍能发掘出输入数据之间的相关性。

本文建立了两个网络，一个为自编码神经网络，可以看作一个五层神经网络，输入数目与输出数目相同，隐藏层神经元个数为$150\rightarrow8\rightarrow150$，各层神经元的激活函数选为Sigmoid函数。其功能和PCA相似之处在于把输入的特征进行进一步的提取。使用时取出自动编码器的前一半作为编码器，输出层接一个Softmax分类器就形成了A-S分类器网络。该网络的隐藏层的输出值正好就是类似池化后的特征值，但其几乎包含了输入向量的所有信息。输出层为8个神经元，正好为输出的8种故障类别。与传统神经网络不同的是，输出层的变为了一个Softmax分类器，网络的具体结构如图
3所示。

\begin{center}
	\includegraphics[scale=0.12, trim=0 0 0 0]{figs/autoencoder_softmax}\\
	\label{fig4}
	\figcaption{传统自动编码深度学习网络架构}
\end{center}

网络训练时分为两部分，首先对自动编码网络训练，将$24$维的训练样本集全部输入，使用批量梯度下降算法进行训练，使输出尽可能的与输入均方误差最小。自编码网络训练完，将编码器结构取出，为后续分类做准备。接下来就是训练A-S分类器网络，将前面训练好的编码器网络的权重和阈值来初始化新构建的神经网络的权值和阈值，重新进行训练。自编码网络结构为$24\rightarrow150\rightarrow8\rightarrow150\rightarrow24$，激活函数为RELU，此时训练的算法为L-BFGS，学习率为0.01，目标函数为使得“交叉熵”最小。交叉熵产生于信息论里面的信息压缩编码技术，是用来衡量两种分布之间的差异性，使交叉熵越小也就是差异性越低即准确率越高。

\subsection{对比A-BP和A-S辨识效果}

在对BP网络和A-S深度学习网络进行实验时，选择其中909组数据作为训练样本集，余下的115组数据作为测试集来进行验证。

基于2.3提出几种分类评价标准，本文对A-BP神经网络和A-S深度学习网络进行对比测试实验。

在24维特征向量输入网络之前，利用自编码网络对其进行特征提取。自编码网络也可以看作一种神经网络，其目标函数就是使输出尽可能的与输入相等，这样既可以在隐含层实现无损压缩。为了验证自编码网络的性能，我们选取其中8维特征观察还原效果，如图4所示。

\begin{center}
	\includegraphics[scale=0.7, trim=0 0 0 0]{figs/autoencoder_restore}\\
	\label{fig5}
	\figcaption{自编码还原效果图}
\end{center}

图4中，红色代表原始数据，蓝色代表自动编码器还原回来的数据。由该图可以看出，编码还原后绝大多数的特征点还是与编码前的特征点比较接近，因此，自编码网络经过多步训练后能够较好的复现输入。也就是说，隐含层提取到的特征包含了输入特征的大部分信息，即可以用隐含层的输出的更加显著的特征向量来代替原网络的高维输入向量。

训练完成后，获得编码后的隐藏层输出的特征如图5所示。

\begin{center}
	\includegraphics[scale=0.7, trim=0 0 0 0]{figs/autoencoder_encoded_features}\\
	\label{fig6}
	\figcaption{自编码网络输出特征}
\end{center}

由图5可以看出自编码后的特征较编码前的特征数量上大幅度下降，而有故障与无故障之间的区分度更加明显。这正是自编码对高维冗余特征压缩使有效特征浮现的结果。不仅在特征数量上有所降低，而且故障点的分布较分散，这样就可以利用分类器实现准确的分类。

\subsubsection{A-BP神经网络实验结果}

由表4可以计算出A-BP网络对于有故障预测的准确率为66.7\%，而对于无故障预测的正确率为78.6\%，错误率也下降为26.1\%。可以看出，相较传统的BP神经网络其在有无故障预测的正确率方面有了一定提高，同时错误率也有所下降，特征经过自编码网络编码后，有效特征被提取出来，提高了传统BP网络的辨识能力。

\begin{center}
	\tabcaption{A-BP实验结果}
	\label{tab:4}
	\begin{tabular} {cccc}\toprule
		\multirow{2}{*}[-2pt]{}&\multirow{2}{*}[-2pt]{}&\multicolumn{2}{c}{预测结果}\\
		\cmidrule(lr){3-4}
		&&有故障&无故障\\\hline
		\multirow{2}{*}[-2pt]{真实结果}&有故障&30&15\\
		&无故障&15&55\\
		\bottomrule
\end{tabular}\end{center}

\subsubsection{A-S深度学习网络实验结果}

训练完自动编码器之后，在隐藏层特征之后加入Softmax分类器，得到最终分类网络结构为$24\rightarrow150\rightarrow24\rightarrow8$，利用表5中的数据带入上面的公式可以得到A-S深度学习网络预测有故障的正确率为82.2\%，预测无故障的正确率为88.5\%，而错误率降低为13.9\%。

\begin{center}
	\tabcaption{A-S实验结果}
	\label{tab:5}
	\begin{tabular} {cccc}\toprule
		\multirow{2}{*}[-2pt]{}&\multirow{2}{*}[-2pt]{}&\multicolumn{2}{c}{预测结果}\\
		\cmidrule(lr){3-4}
		&&有故障&无故障\\\hline
		\multirow{2}{*}[-2pt]{真实结果}&有故障&37&8\\
		&无故障&8&62\\
		\bottomrule
\end{tabular}\end{center}

由上述结果可知，A-S深度学习网络在预测有无故障正确率方面明显优于前面两种网络，此外还大大降低了错误率，由此可以看出该深度学习网络对分均衡分类问题有着良好的分类效果。

\section{引入DropOut与降噪自编码}
从图4也能看出，传统自动编码器对数据的恢复效果一般，而且使用测试集测试自动编码器编码的时候，编码效果明显弱于训练集。这是因为自动编码器对噪声数据有着一定的过拟合。为了解决这个困难，我们引入DropOut与降噪自编码技术。为了便于对比，网络规模和结构与上一章的自动编码器一致。

\subsection{DropOut}

DropOut是一种通用的训练神经网络并能明显降低过拟合的方法。在训练过程中，将神经网络中的神经元按照一定概率$P(d)$丢弃，训练这些稀疏的模型，并去掉权值惩罚项，将其替换为限制权值的截断上限。因为噪声通常表现为高频干扰，用这种方法既可以将对高频干扰的拟合钳位，又可以以较低成本实现模型融合的效果。在测试过程中，将输入校正为为$1-P(d)$倍，使得神经网络传输的数据均值不变。DropOut结构如图6所示。

\begin{center}
	\includegraphics[scale=0.14, trim=0 0 0 0]{figs/dropout}\\
	\label{fig7}
	\figcaption{DropOut结构示意图}
\end{center}

\subsection{降噪自编码}
降噪自编码通过将输入数据加入随机干扰，或将输入数据的某些维度随机置零。训练时要求即便加入了干扰，仍够可以还原输入。通过这种方法，可以使自动编码器无监督地能学习到更加鲁棒的高层特征，克服噪声的干扰，显著减少神经网络对噪声的拟合。降噪自编码的结构示意图如图7所示。

\begin{center}
	\includegraphics[scale=0.14, trim=0 0 0 0]{figs/denoised_autoencoder}\\
	\label{fig8}
	\figcaption{降噪自编码结构示意图}
\end{center}

如图7，在自动编码器训练时，随机对编码器（即输入层）的输入元素随机置0，而解码器要求能够重建原始输入（即未置0的输入）信息。通过实验证明该方法可以大幅消除噪声造成的影响，减弱过拟合。

\subsection{实验与结果分析}

在对改进自动编码器的行实验时，选择900组数据作为训练样本集，余下的124组数据作为测试集来进行验证。为方便比较，使用与之前的自动编码器相同网络结构，将$24$维的训练样本集全部输入。自编码网络结构为$24\rightarrow150\rightarrow8\rightarrow150\rightarrow24$，训练完自动编码器之后，在隐藏层特征之后加入Softmax分类器，得到最终分类网络结构为$24\rightarrow150\rightarrow8\rightarrow8$。激活函数为RELU，训练的算法为L-BFGS，学习率为0.01，目标函数为使得“交叉熵”最小。DropOut 概率选择0.5，在训练编码器的时候加入；降噪时随即丢弃单元时每个节点被丢弃的概率为0.1。

\subsubsection{DropOut自动编码器实验结果}

由表6可以计算出加入DropOut之后网络对于有故障预测的准确率为88.7\%，而对于无故障预测的正确率为84.8\%，错误率也下降为11.3\%。可以看出，使用DropOut 之后可以显著减少过拟合，对样本进行正确拟合之后，泛化能力得到显著改善。

\begin{center}
	\tabcaption{DropOut自动编码器实验结果}
	\label{tab:6}
	\begin{tabular} {cccc}\toprule
		\multirow{2}{*}[-2pt]{}&\multirow{2}{*}[-2pt]{}&\multicolumn{2}{c}{预测结果}\\
		\cmidrule(lr){3-4}
		&&有故障&无故障\\\hline
		\multirow{2}{*}[-2pt]{真实结果}&有故障&39&6\\
		&无故障&7&63\\
		\bottomrule
\end{tabular}\end{center}

\subsubsection{降噪自编码实验结果}

由表7可以计算出降噪自编码对于有故障预测的准确率为85.4\%，而对于无故障预测的正确率为91.5\%，错误率也下降为10.4\%。可以看出，降噪自编码减弱了对噪声的拟合，对数据去噪之后只压缩了有意义的特征，去掉了噪声特征，可以明显增强泛化能力。

\begin{center}
	\tabcaption{降噪自编码实验结果}
	\label{tab:7}
	\begin{tabular} {cccc}\toprule
		\multirow{2}{*}[-2pt]{}&\multirow{2}{*}[-2pt]{}&\multicolumn{2}{c}{预测结果}\\
		\cmidrule(lr){3-4}
		&&有故障&无故障\\\hline
		\multirow{2}{*}[-2pt]{真实结果}&有故障&35&10\\
		&无故障&6&64\\
		\bottomrule
\end{tabular}\end{center}

\subsubsection{DropOut降噪自编码实验结果}

利用表8中的数据可以得到DropOut降噪自编码网络预测有故障的正确率为90.4\%，预测无故障的正确率为88.6\%，而错误率降低为9.6\%。经过降噪自编码与DropOut的共同作用，完善地解决了之前容易过拟合的困难，使准确率达到工业界先进水平。

\begin{center}
	\tabcaption{DropOut降噪自编码实验结果}
	\label{tab:8}
	\begin{tabular} {cccc}\toprule
		\multirow{2}{*}[-2pt]{}&\multirow{2}{*}[-2pt]{}&\multicolumn{2}{c}{预测结果}\\
		\cmidrule(lr){3-4}
		&&有故障&无故障\\\hline
		\multirow{2}{*}[-2pt]{真实结果}&有故障&39&6\\
		&无故障&5&65\\
		\bottomrule
\end{tabular}\end{center}

\section{结\quad 论}

本文使用DropOut降噪自编码，在A-S深度学习网络的基础上，显著降低了分类错误率，达到工业界最先进的水平。这种方法避免了传统基于神经网络的方法容易陷入过拟合的困境，对数据进行深层特征提取，实现了数据降噪，提高了分类神经网络的鲁棒性，将为今后的非传统分类问题提供一个理论依据，并将在深度学习实现故障辨识领域产生深远意义。



\addtolength{\itemsep}{-0.7em}
\bibliographystyle{bib/gbt7714-2005}
\bibliography{bib/reference.bib}
\editor{X~~~~X}
\end{multicols}
\end{document}
界先进水平。

\begin{center}
	\tabcaption{DropOut降噪自编码实验结果}
	\label{tab:8}
	\begin{tabular} {cccc}\toprule
		\multirow{2}{*}[-2pt]{}&\multirow{2}{*}[-2pt]{}&\multicolumn{2}{c}{预测结果}\\
		\cmidrule(lr){3-4}
		&&有故障&无故障\\\hline
		\multirow{2}{*}[-2pt]{真实结果}&有故障&39&6\\
		&无故障&5&65\\
		\bottomrule
\end{tabular}\end{center}


\section{结\quad 论}

本文使用DropOut降噪自编码，利用深度神经网络对大量数据处理表现优良的优势，解决了线性不可分的困难，在A-S深度学习网络的基础上，显著降低了分类错误率，达到工业界最先进的水平。这种方法避免了传统基于神经网络的方法容易陷入过拟合的困境，对数据进行深层特征提取，实现了数据降噪，提高了分类神经网络的鲁棒性，将为今后的非传统分类问题提供一个理论依据，并将在深度学习实现故障辨识领域产生深远意义。



\addtolength{\itemsep}{-0.7em}
\bibliographystyle{bib/gbt7714-2005}
\bibliography{bib/reference.bib}
\editor{X~~~~X}
\end{multicols}
\end{document}
